> ‚ö†Ô∏è **Work in progress** ‚Äì This repository is under active development. APIs, configs, and model logic may change without notice.

# üß† Structural Damage Modeling with Spectral MMVAE & Latent Diffusion

This repository contains modular deep learning pipelines for **structural damage detection and data synthesis** from multimodal inputs such as time-frequency spectrograms and crack masks.

It combines two complementary approaches:

1. **Spectral MMVAE** ‚Äì A Multimodal Variational Autoencoder for realistic data synthesis.
2. **Multi-Modal Latent Diffusion (MLD)** ‚Äì A generative diffusion-based model for realistic data synthesis.
Both try to archieve the same goal. Learn, in a multimodal way, to generate synthetic vabriational data and corresponding damage scenarios as pairs based on real world data from a masonry arch bridge.

---

## üìÅ Repository Structure

```text
DataSynthSHM/
‚îú‚îÄ‚îÄ configs/                # OmegaConf YAMLs for model configs
‚îú‚îÄ‚îÄ scripts/                # SLURM cluster launch scripts
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ bridge_data/        # Shared preprocessing, transforms, IO
‚îÇ   ‚îú‚îÄ‚îÄ diff_pt/            # PyTorch latent diffusion model
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.py        # Full diffusion model architecture
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py        # Training loop and checkpointing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ run.py          # CLI entry point
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ io.py, losses.py, utils.py, vis.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tests/          # Evaluation & reconstruction scripts
‚îÇ   ‚îî‚îÄ‚îÄ mmvae_tf/           # TensorFlow-based Spectral MMVAE
‚îÇ       ‚îú‚îÄ‚îÄ model.py        # Encoders, decoders, and MoE logic
‚îÇ       ‚îú‚îÄ‚îÄ train.py        # MMVAE training logic and loop
‚îÇ       ‚îú‚îÄ‚îÄ run.py          # CLI entry point
‚îÇ       ‚îú‚îÄ‚îÄ losses.py, utils.py, env.py, io.py, vis.py
‚îÇ       ‚îî‚îÄ‚îÄ tests/          # VAE test & visualization utilities
‚îú‚îÄ‚îÄ cache/                  # Cached .npy/.pkl data
‚îú‚îÄ‚îÄ results_diff/           # Diffusion model logs/outputs
‚îú‚îÄ‚îÄ results_mmvae/          # MMVAE model logs/outputs
‚îú‚îÄ‚îÄ logs/                   # Shared training logs
‚îî‚îÄ‚îÄ setup.py                # Editable install
```

---

## üß∞ Features

* Multimodal learning from spectrograms and crack masks
* Modular, extensible design for model components
* Latent diffusion model with conditional sampling
* Framework-hybrid: TensorFlow (MMVAE), PyTorch (Diffusion)
* Compatible with multi-GPU training (MirroredStrategy/DDP)
* Config-driven (OmegaConf-based YAMLs)

---

## 1‚É£ Spectral MMVAE (TensorFlow)\$1

**Module tests (example):**

```bash
python -m mmvae_tf.tests.test_MoE_MMVAE
```

---

## 2‚É£ Latent Diffusion Model (PyTorch)\$1

**Module tests (example):**

```bash
python -m diff_pt.tests.test_reconstruction --ckpt_dir results_diff --n_segments 1
```

---

## üóÇ Data Format

Raw input:

```
Data/
‚îú‚îÄ‚îÄ Data/Test_*/Accel_*.csv        # Time-series accelerometer input
‚îú‚îÄ‚îÄ Labels/Test_*/mask_*.png       # Crack masks
```

Cached and normalized data is stored in `cache/` based on config-defined segment duration and STFT parameters.

---

## üß™ Package Installation & Usage

Install the project as an **editable package** from the repo root:

```bash
pip install -e .
```

This enables:

* Running model code using `python -m mmvae_tf.run` or `diff_pt.run`
* Cross-folder imports between `bridge_data`, `diff_pt`, and `mmvae_tf`
* Reusable modules without reinstalling after edits

> ‚ö†Ô∏è This is required both locally and on the ETH Euler cluster.

---

## üöÄ Running on ETH Euler Cluster

### ‚úÖ Upload Your Code

Use `rsync` to upload your local folder to `/cluster/scratch/<username>/`:

```bash
rsync -av --progress ./DataSynthSHM/ <username>@euler.ethz.ch:/cluster/scratch/<username>/DataSynthSHM/
```

### ‚úÖ Launch a Job with SLURM

```bash
cd /cluster/scratch/<username>/DataSynthSHM
sbatch scripts/diff_run.slurm         # or run_vae.slurm for MMVAE
```

### ‚úÖ Monitor Your Job

```bash
squeue -u $USER                       # show your running jobs
scontrol show job <job_id>           # detailed info
seff <job_id>                        # efficiency summary
```

### ‚úÖ Debug Output

```bash
tail -f diff_run.out           # live stdout from job
cat diff_run.err               # print error output
```

See the full cheatsheet in `Euler_Cluster_cheatsheet.txt` for more.

---

## üõ† Requirements

* Python ‚â• 3.10
* TensorFlow ‚â• 2.15
* PyTorch ‚â• 2.0
* NumPy, SciPy, OpenCV, Plotly, UMAP, Matplotlib, tqdm

Install with:

```bash
pip install -r requirements.txt
```

---

## üß† Author

Developed by **Simon Scandella**
MSc ETH Z√ºrich ‚Äì Structural Health Monitoring & Machine Learning

---

## üìå Note

This repository is under active development. Expect changes in model structure, training logic, and evaluation over time.
